---
title: "Data Science in Life Science - Worksheet 02 Group 1111"
output:
  html_document:
    df_print: paged
date: "2024-04-21"
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)

```

# Question 1

#### Load libraries 
```{r}
library(ggplot2)
#library(tidyverse)
#library(stats)
#library(extraDistr)
#library(MASS) 
#library(reshape2) 
#library(reshape)
```
### Post-hoc power analysis
```{r post-hoc power}
n_ = 20 # Number of subjects in EACH group
delta_ = 0.325 #Mean difference from T-test
sd_ = sd(subset(lung_data$Lung.function, lung_data$Trial.arm == "Control")) #SD from control group
alpha_ = 0.05 #significance level
type_ = "two.sample" #Since we're comparing two groups to one another, 
power.t.test(n=n_, delta=delta_, sd=sd_, sig.level=alpha_, power=NULL, type=type_)
```
### single power test for control/treatment
```{r single power test for control/treatment}
set.seed(123)
control <- rnorm(n=20, mean=0, sd=1)
treatment <- rnorm(n=20, mean=0.5, sd=1)


#p_value <- t.test(treatment, control, mu = 0, alternative = "two.sided", paired = FALSE, conf.level = 0.95)$p.value
p_value <- t.test(treatment, control, type = "two.sided", paired = FALSE, conf.level = 0.95)$p.value
estimate <- t.test(treatment, control, type = "two.sided", paired = FALSE, conf.level = 0.95)$estimate
delta_ <- unname(estimate[1] - estimate[2])
sd_ <- sd(control)
alpha_ <- 0.05
type_ <- "two.sample"
power.t.test(n=20, delta=delta_, sd=sd_, sig.level=alpha_, power=NULL, type=type_)
```
### Repeat power test 10,000 times
```{r}
#Silly loop formulation
df = data.frame(p_value=double(),
                power=double()
                )

for (j in 1:10000) { 
  control <- rnorm(n=20, mean=0, sd=1)
  treatment <- rnorm(n=20, mean=0.5, sd=1)

  p_value_ <- t.test(treatment, control, type = "two.sided", paired = FALSE, conf.level = 0.95)$p.value
  estimate <- t.test(treatment, control, type = "two.sided", paired = FALSE, conf.level = 0.95)$estimate
  delta_ = unname(estimate[1] - estimate[2])
  #sd_ = sd(control)
  sd_ = sqrt(var(control)+var(treatment))
  alpha_ = 0.05
  type_ = "two.sample"
  power_ <- power.t.test(n=20, delta=delta_, sd=sd_, sig.level=0.05, power=NULL, type="two.sample")$power

  df <- rbind(df, data.frame(p_value=p_value_, power=power_))
}
#What would the statistical power be with delta=0.5 and sd=1?
power_true <- power.t.test(n=20, delta=0.5, sd=1, sig.level=0.05, power=NULL, type="two.sample")$power

ggplot(df, aes(x=p_value, y=power)) +
  geom_point() + 
  #plot theoretical statistical power
  geom_hline(aes(yintercept=power_true), color='red') + 
  annotate("text", x=0.75, y=0.36, label= "delta=0.5,sd=1", color='red') +
  labs(title='Ad-hoc power for 10,000 t-tests Control vs Treatment')
```
It doesn't make sense to do a post-hoc power analysis because it will be entirely dependent on your p-value.

